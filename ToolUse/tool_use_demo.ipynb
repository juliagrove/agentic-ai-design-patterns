{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f80d41",
   "metadata": {},
   "source": [
    "# Agentic AI Tool Use Demo with LangChain and Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214613fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "gemini_model = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927a0e8",
   "metadata": {},
   "source": [
    "## 1. Defining Tools using Pydantic Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Definitions\n",
    "class WeatherInput(BaseModel):\n",
    "    city: str = Field(description=\"The city to get weather for\")\n",
    "    unit: str = Field(default=\"celsius\", description=\"Temperature unit: celsius or fahrenheit\")\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    expression: str = Field(description=\"Math expression to evaluate, e.g. '2 + 2'\")\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Search query string\")\n",
    "    max_results: int = Field(default=3, description=\"Maximum number of results to return\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80832ded",
   "metadata": {},
   "source": [
    "### Tool Definitions - LLM sees the docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0528bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(args_schema=WeatherInput)\n",
    "def get_weather(city: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Get the current weather for a given city.\"\"\"\n",
    "    # Simulated response for demo purposes\n",
    "    return f\"Weather in {city}: 22Â°{unit[0].upper()}, partly cloudy.\"\n",
    "\n",
    "@tool(args_schema=CalculatorInput)\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a simple math expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}})  # restricted eval\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "@tool(args_schema=SearchInput)\n",
    "def web_search(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    # Simulated response for demo purposes\n",
    "    results = [f\"Result {i+1} for '{query}'\" for i in range(max_results)]\n",
    "    return \"\\n\".join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734baa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_weather, calculator, web_search]\n",
    "print(\"Tools registered:\", [t.name for t in tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c083c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the tool schemas\n",
    "import json\n",
    "\n",
    "for t in tools:\n",
    "    print(f\"\\nTool: {t.name}\")\n",
    "    print(f\"Description: {t.description}\")\n",
    "    print(f\"Schema: {json.dumps(t.args_schema.model_json_schema(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54170a4f",
   "metadata": {},
   "source": [
    "### Manually Invoking the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef710668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_weather.invoke({\"city\": \"Paris\", \"unit\": \"celsius\"}))\n",
    "print(calculator.invoke({\"expression\": \"15 * 4 + 3\"}))\n",
    "print(web_search.invoke({\"query\": \"Agentic AI\", \"max_results\": 2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe2208",
   "metadata": {},
   "source": [
    "## 2. Binding Tools to Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=gemini_model, temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"LLM with tools bound:\", llm_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d58258",
   "metadata": {},
   "source": [
    "## 3. **Full Loop:** user message -> tool decision -> tool call -> final response from LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8210efb",
   "metadata": {},
   "source": [
    "### Use the LLM to decide which tool to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "user_message = HumanMessage(content=\"What is the weather in Philadelphia, Pennsylvania?\")\n",
    "\n",
    "response = llm_with_tools.invoke([user_message])\n",
    "\n",
    "print(\"LLM Response:\")\n",
    "print(\"Content:\", response.content)\n",
    "print(\"Tool Calls:\", response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5b89f",
   "metadata": {},
   "source": [
    "### Execute the Tool Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Map tool names to tool objects\n",
    "tool_map = {t.name: t for t in tools}\n",
    "\n",
    "# Execute each tool the LLM requested\n",
    "tool_messages = []\n",
    "for tool_call in response.tool_calls:\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    tool_args = tool_call[\"args\"]\n",
    "    tool_result = tool_map[tool_name].invoke(tool_args)\n",
    "    \n",
    "    print(f\"Executed tool: {tool_name}({tool_args}) -> {tool_result}\")\n",
    "    \n",
    "    tool_messages.append(\n",
    "        ToolMessage(content=tool_result, tool_call_id=tool_call[\"id\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70355a7d",
   "metadata": {},
   "source": [
    "### Complete the loop by sending the tool results back to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadeb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = llm_with_tools.invoke(\n",
    "    [user_message] + tool_messages\n",
    ")\n",
    "\n",
    "print(\"Final LLM Response:\")\n",
    "print(\"Content:\", final_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
