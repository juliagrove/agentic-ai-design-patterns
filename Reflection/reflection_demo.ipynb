{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b931d6d2",
   "metadata": {},
   "source": [
    "## Demonstration of the Reflection Pattern for Agentic Systems - general chatbot/assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb75b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b16506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeccc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badae598",
   "metadata": {},
   "source": [
    "### Three prompts for this pattern:\n",
    "- Draft\n",
    "- Critique\n",
    "- Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAFT_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions and help with tasks. Produce\n",
    "a first draft of an answer to the user's question.\n",
    "\"\"\"\n",
    "\n",
    "draft = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", DRAFT_PROMPT),\n",
    "    (\"human\", \"{task}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34494c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITIQUE_PROMPT= \"\"\"\n",
    "You are a strict reviewer. Evaluate the draft response given the task.\n",
    "\n",
    "Return exactly:\n",
    "VERDICT: Pass or Fail\n",
    "\n",
    "IF FAIL then add:\n",
    "ISSUES:\n",
    "- <bullet>\n",
    "- <bullet>\n",
    "\"\"\"\n",
    "\n",
    "critique = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", CRITIQUE_PROMPT),\n",
    "    (\"human\", \"TASK: {task}  DRAFT: {draft}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "REVISE_PROMPT = \"\"\"\n",
    "You are skilled at revising drafts given reviewer feedback.\n",
    "\n",
    "Your instructions, given a task, the first draft and the feedback on the draft do the following:\n",
    "- Fix every issue\n",
    "- Be concise\n",
    "- Output ONLY the revised answer\n",
    "\"\"\"\n",
    "\n",
    "revise = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", REVISE_PROMPT),\n",
    "    (\"human\",  \"TASK: {task} DRAFT: {draft} REVIEW:{review} Write the revised answer:\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9497e29",
   "metadata": {},
   "source": [
    "### Create the LangChain Runnables / Chains\n",
    "#### More simply - feeding the prompt to the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '|' operator creates a RunnableSequence\n",
    "draft_chain = draft | llm\n",
    "critique_chain = critique | llm\n",
    "revise_chain = revise | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82677725",
   "metadata": {},
   "source": [
    "### Reflection Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection(task, max_loops):\n",
    "    # invoke - call the chain\n",
    "    draft = draft_chain.invoke({\"task\": task}).text\n",
    "    print(\"First Draft: \", draft)\n",
    "    \n",
    "    for i in range(max_loops):\n",
    "        review = critique_chain.invoke({\"task\": task, \"draft\": draft}).text\n",
    "        print(f\"Review {i+1}:\\n\", review)\n",
    "        \n",
    "        if \"verdict: pass\" in review.lower():\n",
    "            return draft\n",
    "        \n",
    "        draft = revise_chain.invoke({\"task\":task, \"draft\":draft, \"review\":review}).text\n",
    "        print(f\"Revision {i+1}:\\n\", draft)\n",
    "        \n",
    "    return draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef38d6ff",
   "metadata": {},
   "source": [
    "### Testing the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = \"\"\"I want to learn about the correlation between linear algebra and Artificial Intelligence. \n",
    "\n",
    "Constraints:\n",
    "- 6 sentences max\n",
    "- Assume I understand the basics of linear algebra\n",
    "- Dont get too technical or equation heavy\n",
    "\"\"\"\n",
    "\n",
    "final_answer = reflection(sample_question, max_loops=3)\n",
    "print(\"Final Answer:\\n\", final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
